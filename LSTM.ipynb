{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from random import randint\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "\n",
    "We want to create words vectors so that our deep learning model will be able to process the text data. \n",
    "\n",
    "For simplicity sake, I will be using a pre-trained Word2Vec model to create word vectors for my twitter dataset \n",
    "\n",
    "## GloVe\n",
    "I will be using a pre-trained model, [GloVe](http://nlp.stanford.edu/projects/glove/), which is much more manageable as compared to Google's Word2Vec model. \n",
    "\n",
    "GloVe provides a couple of options, and I will use the matrix that contains 400,000 word vectors (each with a dimensionality of 50) for faster training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word List successfully loaded.\n",
      "Word Vectors successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "wordslist = np.load('C:\\\\Users\\\\Ung Lik Teng\\\\Desktop\\\\CodenData\\\\Machine Learning\\\\NLP\\\\LSTM-Sentiment-Analysis\\\\wordsList.npy')\n",
    "print(\"Word List successfully loaded.\")\n",
    "\n",
    "wordslist = wordslist.tolist()\n",
    "wordslist = [word.decode('UTF-8') for word in wordslist]\n",
    "\n",
    "wordvectors = np.load('C:\\\\Users\\\\Ung Lik Teng\\\\Desktop\\\\CodenData\\\\Machine Learning\\\\NLP\\\\LSTM-Sentiment-Analysis\\\\wordVectors.npy')\n",
    "print(\"Word Vectors successfully loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_model = pd.read_csv(\"C:/Users/Ung Lik Teng/Desktop/CodenData/Machine Learning/NLP/cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets: 99989\n",
      "Total number of words: 693111\n",
      "Average number of words per tweets: 6.93187250598\n"
     ]
    }
   ],
   "source": [
    "num_words = sum(df_model.clean_count_words.values)\n",
    "num_tweets = df_model.shape[0]\n",
    "print('Total number of tweets:', num_tweets)\n",
    "print('Total number of words:', num_words)\n",
    "print('Average number of words per tweets:', num_words/num_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Frequency')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f5413fa710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_model.clean_count_words.values,50)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the average number of words per tweets and the histogram, it's safe to say most tweets will fall under 10 words after cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SeqLength = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_small = df_model.sample(200)\n",
    "df_small = df_small.reset_index(drop=True)\n",
    "text_only = df_small.clean_text\n",
    "text_only = text_only.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_only = text_only.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating ids/ Word Vectors for all tweets  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = np.zeros((250, 10), dtype = 'int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_index = 0\n",
    "\n",
    "for tweet in text_only:\n",
    "    seq_index = 0\n",
    "    for word in tweet.split():\n",
    "        try:\n",
    "            ids[tweet_index][seq_index] = wordslist.index(word)\n",
    "        except ValueError:\n",
    "            ids[tweet_index][seq_index] = 399999\n",
    "        seq_index = seq_index + 1\n",
    "        if seq_index >= SeqLength:\n",
    "            break\n",
    "    tweet_index = tweet_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 30632,   7392,    413, ...,      0,      0,      0],\n",
       "       [  1906, 399999, 399999, ...,    974, 399999, 399999],\n",
       "       [  2357,    117,  14115, ...,      0,      0,      0],\n",
       "       ..., \n",
       "       [     0,      0,      0, ...,      0,      0,      0],\n",
       "       [     0,      0,      0, ...,      0,      0,      0],\n",
       "       [     0,      0,      0, ...,      0,      0,      0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check if ids matrix is created correctly \n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.Sentiment.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining Helper functiom \n",
    "from random import randint\n",
    "\n",
    "def getTrainBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, SeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(1,160)\n",
    "        if (df_small.Sentiment.values[num-1] == 1):\n",
    "            labels.append([1,0])\n",
    "        else:\n",
    "            labels.append([0,1])\n",
    "        arr[i-1] = ids[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, SeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(161,200)\n",
    "        if (df_small.Sentiment.values[num-1] == 1):\n",
    "            labels.append([1,0])\n",
    "        else:\n",
    "            labels.append([0,1])\n",
    "        arr[i-1] = ids[num-1:num]\n",
    "    return arr, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the LSTM Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Defining Hyperparameters \n",
    "batchSize = 20\n",
    "lstmUnits = 64\n",
    "numClasses = 2\n",
    "iterations = 100000\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Defining Constant\n",
    "SeqLength = 10\n",
    "embedding_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Defining Placeholder\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, SeqLength])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Defining Data\n",
    "data = tf.Variable(tf.zeros([batchSize, SeqLength, embedding_dim]),dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordvectors,input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Definint LSTM Cell\n",
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstm_cell = tf.contrib.rnn.DropoutWrapper(cell=lstm_cell, output_keep_prob= 0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstm_cell, data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape= [numClasses]))\n",
    "value = tf.transpose(value, [1,0,2])\n",
    "last = tf.gather(value, int(value.get_shape()[0])-1)\n",
    "prediction = (tf.matmul(last,weight)+ bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-42c76bf4ef6d>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction, labels= labels))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(iterations):\n",
    "    #Next Batch of reviews\n",
    "    nextBatch, nextBatchLabels = getTrainBatch();\n",
    "    sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this batch: 64.9999976158\n",
      "Accuracy for this batch: 64.9999976158\n",
      "Accuracy for this batch: 40.000000596\n",
      "Accuracy for this batch: 69.9999988079\n",
      "Accuracy for this batch: 60.0000023842\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 64.9999976158\n",
      "Accuracy for this batch: 85.0000023842\n",
      "Accuracy for this batch: 64.9999976158\n",
      "Accuracy for this batch: 50.0\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "iterations = 10\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch();\n",
    "    print(\"Accuracy for this batch:\", (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
