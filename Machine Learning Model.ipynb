{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from time import time\n",
    "from pprint import pprint \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(\"C:/Users/Ung Lik Teng/Desktop/CodenData/Machine Learning/NLP/cleaned.csv\")\n",
    "sanders_df = pd.read_csv(\"C:/Users/Ung Lik Teng/Desktop/CodenData/Machine Learning/NLP/sanders_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full = df_full.drop('clean_count_words', 1)\n",
    "sanders_df = sanders_df.drop('clean_count_words', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99989, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3424, 8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanders_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here we are using a mini sample of 200 datapoints from the original datsets\n",
    "df_model = df_full.sample(200)\n",
    "df_model = df_model.reset_index(drop = True)\n",
    "sanders_df_model = sanders_df.sample(200)\n",
    "sanders_df_model = sanders_df_model.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ColumnExtractor(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        return X[self.cols]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_model.drop('Sentiment', axis=1), df_model.Sentiment, test_size=0.2, random_state=37, stratify = df_model.Sentiment )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 7)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Based on https://www.kaggle.com/bertcarremans/predicting-sentiment-with-text-features?scriptVersionId=2139318/code\n",
    "def grid_vect(clf, parameters_clf, X_train, X_test, parameters_text=None, vect=None, is_w2v=False):\n",
    "    \n",
    "    textcountscols = ['count_capital_words','count_excl_quest_marks','count_hashtags'\n",
    "                      ,'count_mentions','count_urls','count_words']\n",
    "    \n",
    "    if is_w2v:\n",
    "        w2vcols = []\n",
    "        for i in range(SIZE):\n",
    "            w2vcols.append(i)\n",
    "        features = FeatureUnion([('textcounts', ColumnExtractor(cols=textcountscols))\n",
    "                                 , ('w2v', ColumnExtractor(cols=w2vcols).fit(X_train))])\n",
    "    else:\n",
    "         features = FeatureUnion([('textcounts', ColumnExtractor(cols=textcountscols))\n",
    "                                 , ('pipe', Pipeline([('cleantext', ColumnExtractor(cols='clean_text').fit(X_train)), ('vect', vect)]))])\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('features', features)\n",
    "        , ('clf', clf)\n",
    "    ])\n",
    "    \n",
    "    # Join the parameters dictionaries together\n",
    "    parameters = dict()\n",
    "    if parameters_text:\n",
    "        parameters.update(parameters_text)\n",
    "    parameters.update(parameters_clf)\n",
    "\n",
    "    # Make sure you have scikit-learn version 0.19 or higher to use multiple scoring metrics\n",
    "    grid_search = GridSearchCV(pipeline, parameters, verbose=1, cv=5)\n",
    "    \n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best CV score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    print(\"Test score with best_estimator_: %0.3f\" % grid_search.best_estimator_.score(X_test, y_test))\n",
    "    print(\"\\n\")\n",
    "    print(\"Classification Report Test Data\")\n",
    "    print(classification_report(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "                        \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter grid settings for the vectorizers (Count and TFIDF)\n",
    "parameters_vect = {\n",
    "    'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
    "    'features__pipe__vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'features__pipe__vect__min_df': (1,2)\n",
    "}\n",
    "\n",
    "\n",
    "# Parameter grid settings for MultinomialNB\n",
    "parameters_mnb = {\n",
    "    'clf__alpha': (0.25, 0.5, 0.75)\n",
    "}\n",
    "\n",
    "\n",
    "# Parameter grid settings for LogisticRegression\n",
    "parameters_logreg = {\n",
    "    'clf__C': (0.25, 0.5, 1.0),\n",
    "    'clf__penalty': ('l1', 'l2')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "logisticsreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countVec = CountVectorizer()\n",
    "tfidfVec= TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "done in 3.423s\n",
      "\n",
      "Best CV score: 0.675\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.25\n",
      "\tfeatures__pipe__vect__max_df: 0.25\n",
      "\tfeatures__pipe__vect__min_df: 2\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 1)\n",
      "Test score with best_estimator_: 0.625\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.65      0.59        17\n",
      "          1       0.70      0.61      0.65        23\n",
      "\n",
      "avg / total       0.64      0.62      0.63        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:    3.3s finished\n"
     ]
    }
   ],
   "source": [
    "mnb_countVec = grid_vect(mnb,parameters_mnb,X_train, X_test, parameters_text = parameters_vect, vect = countVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "done in 5.085s\n",
      "\n",
      "Best CV score: 0.688\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.5\n",
      "\tfeatures__pipe__vect__max_df: 0.25\n",
      "\tfeatures__pipe__vect__min_df: 2\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 2)\n",
      "Test score with best_estimator_: 0.650\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.59      0.59        17\n",
      "          1       0.70      0.70      0.70        23\n",
      "\n",
      "avg / total       0.65      0.65      0.65        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:    4.9s finished\n"
     ]
    }
   ],
   "source": [
    "mnb_tfidfVec = grid_vect(mnb, parameters_mnb, X_train, X_test, parameters_vect, vect = tfidfVec)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.25, 0.5, 1.0),\n",
      " 'clf__penalty': ('l1', 'l2'),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "done in 6.196s\n",
      "\n",
      "Best CV score: 0.681\n",
      "Best parameters set:\n",
      "\tclf__C: 0.25\n",
      "\tclf__penalty: 'l2'\n",
      "\tfeatures__pipe__vect__max_df: 0.25\n",
      "\tfeatures__pipe__vect__min_df: 2\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 1)\n",
      "Test score with best_estimator_: 0.625\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.35      0.44        17\n",
      "          1       0.63      0.83      0.72        23\n",
      "\n",
      "avg / total       0.62      0.62      0.60        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:    6.1s finished\n"
     ]
    }
   ],
   "source": [
    "lr_countVec = grid_vect(logisticsreg,parameters_logreg,X_train, X_test,parameters_text = parameters_vect, vect = countVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.25, 0.5, 1.0),\n",
      " 'clf__penalty': ('l1', 'l2'),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "done in 5.472s\n",
      "\n",
      "Best CV score: 0.675\n",
      "Best parameters set:\n",
      "\tclf__C: 1.0\n",
      "\tclf__penalty: 'l2'\n",
      "\tfeatures__pipe__vect__max_df: 0.25\n",
      "\tfeatures__pipe__vect__min_df: 2\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 2)\n",
      "Test score with best_estimator_: 0.700\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.65      0.65        17\n",
      "          1       0.74      0.74      0.74        23\n",
      "\n",
      "avg / total       0.70      0.70      0.70        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:    5.4s finished\n"
     ]
    }
   ],
   "source": [
    "lr_tfidfVec = grid_vect(logisticsreg,parameters_logreg,X_train, X_test,parameters_text = parameters_vect, vect = tfidfVec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 50\n",
    "\n",
    "X_train['wordlist'] = X_train.clean_text.apply(lambda x: word_tokenize(x))\n",
    "X_test['wordlist'] = X_test.clean_text.apply(lambda x: word_tokenize(x))\n",
    "\n",
    "w2v_model = gensim.models.Word2Vec(X_train.wordlist\n",
    "                                  , min_count= 1\n",
    "                                  , size = SIZE\n",
    "                                  , window = 5\n",
    "                                  , workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_avg_w2v_vector(w2v_dict, tweet):\n",
    "    list_of_word_vectors = [w2v_dict[w] for w in tweet if w in w2v_dict.vocab.keys()]\n",
    "    \n",
    "    if len(list_of_word_vectors) == 0:\n",
    "        result = [0.0]*SIZE\n",
    "    else:\n",
    "        result = np.sum(list_of_word_vectors, axis=0) / len(list_of_word_vectors)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_w2v = X_train['wordlist'].apply(lambda x: compute_avg_w2v_vector(w2v_model.wv,x))\n",
    "X_test_w2v = X_test['wordlist'].apply(lambda x: compute_avg_w2v_vector(w2v_model.wv,x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_w2v = pd.DataFrame(X_train_w2v.values.tolist(), index= X_train.index)\n",
    "X_test_w2v = pd.DataFrame(X_test_w2v.values.tolist(), index= X_test.index)\n",
    "\n",
    "# Concatenate the TextCounts variables with w2v and drop the clean text and wordlist columns\n",
    "X_train_w2v = pd.concat([X_train_w2v, X_train.drop(['clean_text', 'wordlist'], axis=1)], axis=1)\n",
    "X_test_w2v = pd.concat([X_test_w2v, X_test.drop(['clean_text', 'wordlist'], axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.25, 0.5, 1.0), 'clf__penalty': ('l1', 'l2')}\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "done in 0.337s\n",
      "\n",
      "Best CV score: 0.562\n",
      "Best parameters set:\n",
      "\tclf__C: 0.25\n",
      "\tclf__penalty: 'l1'\n",
      "Test score with best_estimator_: 0.675\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.29      0.43        17\n",
      "          1       0.65      0.96      0.77        23\n",
      "\n",
      "avg / total       0.73      0.68      0.63        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "logreg_w2v = grid_vect(logisticsreg, parameters_logreg, X_train_w2v, X_test_w2v, is_w2v=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sander Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sanders_df_model.drop('Sentiment', axis=1), sanders_df_model.Sentiment, test_size=0.3, random_state=37, stratify = sanders_df_model.Sentiment )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "done in 5.901s\n",
      "\n",
      "Best CV score: 0.679\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.75\n",
      "\tfeatures__pipe__vect__max_df: 0.25\n",
      "\tfeatures__pipe__vect__min_df: 2\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 1)\n",
      "Test score with best_estimator_: 0.583\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.20      0.08      0.12        12\n",
      "          0       0.63      0.87      0.73        39\n",
      "          1       0.00      0.00      0.00         9\n",
      "\n",
      "avg / total       0.45      0.58      0.50        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:    5.8s finished\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes with Count Vectorizer \n",
    "mnb_countVec = grid_vect(mnb,parameters_mnb,X_train, X_test, parameters_text = parameters_vect, vect = countVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "done in 5.098s\n",
      "\n",
      "Best CV score: 0.664\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.25\n",
      "\tfeatures__pipe__vect__max_df: 0.25\n",
      "\tfeatures__pipe__vect__min_df: 2\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 2)\n",
      "Test score with best_estimator_: 0.700\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.62      0.42      0.50        12\n",
      "          0       0.73      0.95      0.82        39\n",
      "          1       0.00      0.00      0.00         9\n",
      "\n",
      "avg / total       0.60      0.70      0.63        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:    5.0s finished\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes with Tfidf Vectorizer\n",
    "mnb_tfidfVec = grid_vect(mnb, parameters_mnb, X_train, X_test, parameters_vect, vect = tfidfVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.25, 0.5, 1.0),\n",
      " 'clf__penalty': ('l1', 'l2'),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "done in 14.077s\n",
      "\n",
      "Best CV score: 0.657\n",
      "Best parameters set:\n",
      "\tclf__C: 0.5\n",
      "\tclf__penalty: 'l2'\n",
      "\tfeatures__pipe__vect__max_df: 0.25\n",
      "\tfeatures__pipe__vect__min_df: 2\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 1)\n",
      "Test score with best_estimator_: 0.617\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.25      0.08      0.12        12\n",
      "          0       0.64      0.92      0.76        39\n",
      "          1       0.00      0.00      0.00         9\n",
      "\n",
      "avg / total       0.47      0.62      0.52        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:   14.0s finished\n",
      "C:\\Users\\Ung Lik Teng\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression with Count Vectorizer \n",
    "lr_countVec = grid_vect(logisticsreg,parameters_logreg,X_train, X_test,parameters_text = parameters_vect, vect = countVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.25, 0.5, 1.0),\n",
      " 'clf__penalty': ('l1', 'l2'),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "done in 9.158s\n",
      "\n",
      "Best CV score: 0.621\n",
      "Best parameters set:\n",
      "\tclf__C: 0.25\n",
      "\tclf__penalty: 'l1'\n",
      "\tfeatures__pipe__vect__max_df: 0.25\n",
      "\tfeatures__pipe__vect__min_df: 1\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 1)\n",
      "Test score with best_estimator_: 0.650\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00        12\n",
      "          0       0.65      1.00      0.79        39\n",
      "          1       0.00      0.00      0.00         9\n",
      "\n",
      "avg / total       0.42      0.65      0.51        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:    9.0s finished\n",
      "C:\\Users\\Ung Lik Teng\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression with Tfidf Vectorizer\n",
    "lr_tfidfVec = grid_vect(logisticsreg,parameters_logreg,X_train, X_test,parameters_text = parameters_vect, vect = tfidfVec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
